Lead Scoring Engine - Technische Entscheidungen & Einschätzungen
=================================================================

Im Rahmen der Coding Challenge - Antworten auf technische Fragestellungen


1. TECH-STACK IM CRM/ERP KONTEXT
================================

Gewählter Stack:
- Backend: Django 5.0 + Django REST Framework
- Frontend: React 18 + Vite + TypeScript
- Datenbank: SQLite (Dev) / PostgreSQL (Production)

Begründung:

A) Backend - Django
   Pro:
   - Admin Panel out-of-the-box → Schnelle Datenverwaltung für Sales-Teams
   - ORM mit Migrations → Schema-Änderungen einfach versionierbar
   - Django REST Framework → Standard für Business-APIs
   - Batteries included (Auth, Sessions, Middleware)
   - Python → Data Science / ML Integration einfach
   
   Kontext CRM/ERP:
   - Schnelle Entwicklung komplexer Business Logic
   - Gut skalierbar (Instagram, Disqus nutzen Django)
   - Große Community für Enterprise-Features
   - GDPR/Compliance Tools verfügbar

B) Frontend - React + TypeScript
   Pro:
   - Component-basiert → Wiederverwendbar für CRM-Module
   - TypeScript → Weniger Bugs bei komplexen Datenstrukturen
   - Große Auswahl an Business-UI Libraries (AG Grid, Material UI)
   - React Query / TanStack → Perfekt für datenintensive Apps
   
   Kontext CRM/ERP:
   - CRMs = viele Tabellen, Forms, Dashboards → React Components ideal
   - TypeScript reduziert Fehler bei komplexen Sales-Workflows
   - Einfache Integration mit Charts (Recharts, Chart.js)

C) Alternative Stacks für CRM/ERP:
   - Laravel (PHP) + Vue.js → Auch sehr verbreitet, gutes Ecosystem
   - .NET Core + Angular → Enterprise-Standard, Microsoft-Ökosystem
   - Node.js (NestJS) + React → Full-Stack TypeScript
   
   Warum Django gewählt:
   - Schnellere MVP-Entwicklung als .NET
   - Besseres Admin-Panel als Laravel
   - Python besser für ML/Analytics als PHP/C#


2. END-TO-END INTERFACE
=======================

Gewählte Variante: UI (Web Application)

Begründung:
- Sales-Teams arbeiten primär visuell (Dashboards, Listen, Scores)
- Lead-Scoring muss intuitiv verständlich sein
- Schnelle Übersicht wichtiger als Terminal-Zugriff

Flow aus Sicht eines Sales-Users:

1. Dashboard öffnen (http://localhost:5173)
   → Sieht sofort alle Leads sortiert nach Score
   
2. High-Score Leads (≥70) sind farblich hervorgehoben
   → Visueller Fokus auf Key Accounts
   
3. User klickt "Neuen Lead anlegen"
   → Formular mit Dropdown-Feldern (Budget, Industry, etc.)
   
4. Score wird live berechnet während der Eingabe
   → Preview: "Dieser Lead hat Score 85 → Key Account!"
   
5. Nach Speichern: Zurück zur Liste
   → Lead erscheint automatisch in der Tabelle (Polling)
   
6. Liste aktualisiert sich alle 10 Sekunden
   → Team sieht neue Leads von Kollegen in Echtzeit

Alternative Interfaces:
- CLI: Gut für Admins, schlecht für Sales (nicht visuell genug)
- API-Only: Gut für Integrationen, aber Sales braucht UI
- Mobile App: Sinnvoll als Erweiterung, aber Web ist Standard

Warum keine CLI:
- Sales-Teams sind keine Entwickler
- Scoring muss "auf einen Blick" erkennbar sein
- Tables/Dashboards sind Standard in Sales-Tools


3. OBSERVABILITY (Logs, Metriken, Traces)
=========================================

A) Strukturierte Logs (Was implementiert werden sollte):

Backend (Django):
```python
import logging
logger = logging.getLogger(__name__)

# Bei Lead-Erstellung:
logger.info(
    "Lead created",
    extra={
        "lead_id": lead.id,
        "score": lead.score,
        "tenant_id": lead.tenant_id,
        "user_id": request.user.id,
        "timestamp": datetime.now()
    }
)

# Bei Score-Berechnung:
logger.debug(
    "Score calculated",
    extra={
        "lead_id": lead.id,
        "budget_score": 30,
        "company_size_score": 20,
        "industry_score": 20,
        "urgency_score": 15,
        "total_score": 85
    }
)

# Bei Fehlern:
logger.error(
    "Lead creation failed",
    extra={
        "error": str(e),
        "tenant_id": tenant_id,
        "payload": request.data
    }
)
```

Frontend (React):
```typescript
// Custom Error Boundary
console.error({
  event: "lead_fetch_failed",
  error: error.message,
  timestamp: Date.now(),
  user_session: sessionId
})
```

B) Metriken (Was gemessen werden sollte):

Business Metriken:
- Anzahl erstellter Leads pro Tag
- Durchschnittlicher Lead-Score
- Anzahl Key Accounts (Score ≥ 70)
- Conversion Rate (Leads → Deals)
- Time-to-Contact (Wie lange bis Sales kontaktiert)

Performance Metriken:
- API Response Time (p50, p95, p99)
- Database Query Time
- Frontend Load Time
- Polling Overhead

Technische Metriken:
- HTTP Errors (4xx, 5xx)
- Database Connection Pool Usage
- Memory Usage (Django Worker)
- CPU Usage

C) Alerting (Was überwacht werden sollte):

Kritisch (sofort alarmieren):
- API Error Rate > 5%
- Database nicht erreichbar
- Response Time > 2 Sekunden (p95)
- Keine Leads mehr erstellt seit 1 Stunde (Production)

Wichtig (innerhalb 30 Min):
- Memory Usage > 80%
- Disk Space < 10%
- Anzahl High-Score Leads sinkt drastisch (Scoring-Bug?)

Monitoring (täglich prüfen):
- Durchschnittlicher Score ändert sich stark
- Neue Leads pro Tag sinkt um > 50%
- Bestimmte Industries dominieren (Scoring-Bias?)

D) Tools für Production:

Logs:
- ELK Stack (Elasticsearch, Logstash, Kibana)
- oder: Grafana Loki + Promtail

Metriken:
- Prometheus + Grafana
- oder: Datadog / New Relic

Traces:
- OpenTelemetry + Jaeger
- oder: Sentry für Error Tracking

APM (Application Performance Monitoring):
- Django: django-prometheus
- Frontend: Sentry Browser SDK


4. FRONTEND STATE MANAGEMENT
============================

A) Gewählte Architektur:

State Management:
- useState für lokalen Component-State
- Custom Hook (useLeadsPolling) für Data Fetching
- Keine Redux/Zustand → Overkill für MVP

Fetching-Strategie:
- HTTP Polling (alle 10 Sekunden)
- Fetch API (native, kein axios nötig)
- Pagination-Support vorbereitet (data.results || data)

Fehler-/Loading-Zustände:
```typescript
const { leads, loading, error, refetch } = useLeadsPolling()

// Loading State:
if (loading && leads.length === 0) {
  return <LoadingSpinner />
}

// Error State:
if (error) {
  return <ErrorMessage error={error} onRetry={refetch} />
}

// Success State:
return <LeadTable leads={leads} />
```

B) Warum NICHT React Query?

Für dieses Projekt:
- Polling-Logik ist simpel (setInterval)
- Keine komplexen Cache-Strategien nötig
- Keine Mutations mit Optimistic Updates
- Custom Hook reicht vollkommen

Wann React Query Sinn macht:
- Viele verschiedene Endpoints
- Komplexe Cache-Invalidierung
- Optimistic Updates (Lead bearbeiten → sofort UI updaten)
- Infinite Scrolling / Pagination
- Background Refetching

C) Optimistic Updates (nicht implementiert, aber wie):

Beispiel: Lead bearbeiten
```typescript
const { mutate } = useMutation({
  mutationFn: updateLead,
  
  // Sofort UI updaten (optimistisch):
  onMutate: async (updatedLead) => {
    await queryClient.cancelQueries(['leads'])
    const previous = queryClient.getQueryData(['leads'])
    
    queryClient.setQueryData(['leads'], (old) => 
      old.map(lead => lead.id === updatedLead.id ? updatedLead : lead)
    )
    
    return { previous }
  },
  
  // Bei Fehler: Rollback:
  onError: (err, variables, context) => {
    queryClient.setQueryData(['leads'], context.previous)
  },
  
  // Nach Server-Response: Re-Fetch:
  onSettled: () => {
    queryClient.invalidateQueries(['leads'])
  }
})
```

D) Error Boundaries:

Nicht implementiert, aber sinnvoll:
```typescript
class ErrorBoundary extends React.Component {
  state = { hasError: false }
  
  static getDerivedStateFromError(error) {
    return { hasError: true }
  }
  
  componentDidCatch(error, errorInfo) {
    // Log zu Sentry
    console.error('Component Error:', error, errorInfo)
  }
  
  render() {
    if (this.state.hasError) {
      return <h1>Etwas ist schiefgelaufen.</h1>
    }
    return this.props.children
  }
}
```

E) Loading Skeleton:

Bessere UX statt Spinner:
```tsx
{loading ? (
  <TableSkeleton rows={10} />  // Graue Platzhalter
) : (
  <LeadTable leads={leads} />
)}
```


5. PERFORMANCE & SKALIERUNG
===========================

A) Aktuelle Engpässe im Prototyp:

1. Polling alle 10 Sekunden
   - Problem: Bei 100 Usern = 10 Requests/Sekunde zum Backend
   - Lösung: WebSockets oder Server-Sent Events (SSE)
   
2. Keine Pagination
   - Problem: Bei 10.000 Leads wird komplette Liste geladen
   - Lösung: Django Pagination + Infinite Scroll
   
3. SQLite
   - Problem: Keine Concurrent Writes, limitiertes Caching
   - Lösung: PostgreSQL mit Connection Pooling
   
4. Score-Berechnung bei jedem Save
   - Problem: Bei Bulk-Import 1000x Lead.save() = langsam
   - Lösung: Bulk-Create mit bulk_update() für Scores
   
5. Kein Caching
   - Problem: Gleiche Leads-Liste wird jedes Mal neu berechnet
   - Lösung: Redis für häufig abgefragte Daten

B) Skalierungs-Szenarien:

Szenario 1: 1.000 Leads, 10 User
- Aktueller Stand: Funktioniert problemlos
- Bottleneck: Keiner
- Action: Nichts ändern

Szenario 2: 100.000 Leads, 100 User
- Bottleneck: SQLite, Kein Caching, Polling-Overhead
- Action:
  1. PostgreSQL mit Indexing (score, created_at, tenant_id)
  2. Redis für Lead-Liste Cache (TTL 30 Sekunden)
  3. WebSockets statt Polling
  4. API Pagination (100 Leads pro Seite)

Szenario 3: 1 Mio. Leads, 1.000 User (Enterprise)
- Bottleneck: Monolith, Single DB, Keine Load Balancing
- Action:
  1. Read Replicas für Queries
  2. Celery für async Score-Berechnung
  3. CDN für Frontend
  4. Database Sharding nach Tenant-ID
  5. Elasticsearch für Full-Text Search
  6. Load Balancer (Nginx) + Multiple Gunicorn Workers

C) Konkrete Optimierungen:

Database Indexing:
```python
class Lead(models.Model):
    score = IntegerField(db_index=True)  # Index für Sortierung
    tenant = ForeignKey(Tenant, db_index=True)  # Index für Filter
    created_at = DateTimeField(db_index=True)
    
    class Meta:
        indexes = [
            Index(fields=['tenant', '-score']),  # Composite Index
            Index(fields=['tenant', '-created_at'])
        ]
```

Query Optimization:
```python
# Schlecht:
leads = Lead.objects.all()
for lead in leads:
    print(lead.tenant.name)  # N+1 Query Problem!

# Gut:
leads = Lead.objects.select_related('tenant').all()  # 1 Query
```

Caching:
```python
from django.core.cache import cache

def get_leads(tenant_id):
    cache_key = f'leads_tenant_{tenant_id}'
    leads = cache.get(cache_key)
    
    if not leads:
        leads = Lead.objects.filter(tenant_id=tenant_id)
        cache.set(cache_key, leads, timeout=30)  # 30 Sekunden
    
    return leads
```

Frontend Code-Splitting:
```typescript
// Lazy Loading für große Components
const LeadTable = lazy(() => import('./components/LeadTable'))
const Dashboard = lazy(() => import('./pages/Dashboard'))
```

D) Load Testing (Was gemacht werden sollte):

Tools:
- Locust (Python) für Backend Load Tests
- k6 für API Performance Tests
- Lighthouse für Frontend Performance

Test-Szenarien:
1. 100 concurrent users laden Lead-Liste
2. 50 users erstellen gleichzeitig Leads
3. Polling-Last: 100 requests/Sekunde
4. Bulk-Import: 10.000 Leads auf einmal


6. PRODUKTNUTZEN & IMPACT MEASUREMENT
=====================================

A) Sales-Personas die profitieren:

Persona 1: Sales Development Representative (SDR)
- Problem: Bekommt 50 Leads pro Tag, weiß nicht welche priorisieren
- Lösung: Leads sind automatisch nach Score sortiert
- Nutzen: Fokussiert sich auf Top 20% (Key Accounts mit Score ≥ 70)
- Impact: 30% mehr Conversions durch bessere Priorisierung

Persona 2: Account Executive (AE)
- Problem: Will nur "heiße" Leads, keine Zeit für Spam
- Lösung: Filtert nur Leads mit Score ≥ 85
- Nutzen: Kontaktiert nur vielversprechende Prospects
- Impact: 50% weniger verschwendete Zeit

Persona 3: Sales Manager
- Problem: Keine Übersicht welche Leads im Funnel sind
- Lösung: Dashboard mit Avg. Score, Top Leads, Industry-Verteilung
- Nutzen: Datenbasierte Entscheidungen statt Bauchgefühl
- Impact: Bessere Team-Performance durch richtige Lead-Verteilung

Persona 4: Marketing Team
- Problem: Weiß nicht welche Kampagnen gute Leads bringen
- Lösung: Score-Tracking nach Lead-Source
- Nutzen: Fokus auf Kanäle die High-Quality Leads bringen
- Impact: 20% höherer Marketing-ROI

B) Impact Measurement - KPIs:

Primäre Metriken (Business Impact):
1. Lead-to-Deal Conversion Rate
   - Vorher: 5% aller Leads werden zu Deals
   - Nachher: 15% der High-Score Leads werden zu Deals
   - Messung: COUNT(deals) / COUNT(leads WHERE score >= 70)

2. Time-to-Contact
   - Vorher: 48 Stunden durchschnittlich
   - Nachher: 6 Stunden für High-Score Leads
   - Messung: AVG(contact_date - created_at) WHERE score >= 70

3. Sales Velocity (Deal-Geschwindigkeit)
   - Vorher: 30 Tage von Lead → Deal
   - Nachher: 20 Tage für gescorte Leads
   - Messung: AVG(deal_closed_date - lead_created_date)

4. Revenue per Lead
   - Vorher: €10.000 Average Deal Size
   - Nachher: €15.000 für High-Score Leads
   - Messung: SUM(deal_value) / COUNT(leads)

Sekundäre Metriken (Produktnutzung):
1. Adoption Rate
   - Messung: % der Sales-Mitarbeiter die Tool täglich nutzen
   - Ziel: >80% nach 4 Wochen

2. Feature Usage
   - Messung: Wie oft wird "Sortierung nach Score" genutzt?
   - Messung: Wie viele Leads werden pro User pro Tag angeschaut?

3. Score Distribution
   - Messung: Wie viele Leads sind in welchem Score-Bereich?
   - Problem-Detektion: Wenn alle Leads Score 50 haben → Formel anpassen

4. False Positives
   - Messung: Wie viele High-Score Leads werden NICHT kontaktiert?
   - Feedback: Sales-Team markiert "Scoring war falsch"

C) A/B Testing (Was getestet werden sollte):

Test 1: Score-Formel
- Gruppe A: Aktuelle Formel (Budget 30%, Size 30%, Industry 20%, Urgency 20%)
- Gruppe B: Neue Formel (Budget 40%, Size 20%, Industry 20%, Urgency 20%)
- Metrik: Welche Gruppe hat höhere Conversion Rate?

Test 2: Urgency-Gewichtung
- These: "Immediately" sollte mehr Punkte geben als "This Week"
- A: Immediately = 20 Punkte
- B: Immediately = 25 Punkte
- Metrik: Sind "Immediately"-Leads wirklich besser?

Test 3: UI-Design
- A: Tabelle mit Farbcodierung
- B: Card-View mit großem Score-Badge
- Metrik: Welche Variante führt zu schnellerer Kontaktierung?

D) Success Stories (Wie kommuniziert werden sollte):

Case Study Template:
```
Firma: Tech Startup GmbH
Team-Größe: 5 Sales-Mitarbeiter
Problem: 200 Leads/Woche, chaotische Priorisierung

Vorher (ohne Lead Scoring):
- 3% Conversion Rate
- 72h Time-to-Contact
- €8.000 Average Deal Size

Nachher (mit Lead Scoring):
- 12% Conversion Rate (+300%)
- 8h Time-to-Contact (-89%)
- €12.000 Average Deal Size (+50%)

ROI: +€240.000 Revenue im ersten Quartal
```

E) Feedback-Loop implementieren:

1. Sales markiert Lead als "War guter Score" oder "War schlechter Score"
2. System lernt: Welche Kriterien waren wirklich wichtig?
3. Score-Formel wird angepasst (ML-basiert)
4. A/B Test der neuen Formel
5. Roll-out wenn besser


FAZIT
=====

Diese Anwendung ist als MVP konzipiert, das zeigt:
- Wie Lead-Scoring technisch umgesetzt werden kann
- Welche Architektur-Entscheidungen getroffen wurden
- Wo die Skalierungs-Grenzen liegen
- Wie der Business-Impact gemessen werden kann

Nächste Schritte für Production:
1. PostgreSQL + Redis
2. WebSockets statt Polling
3. React Query für besseres State Management
4. Observability Stack (Prometheus, Grafana, Sentry)
5. A/B Testing Framework
6. ML-basierte Score-Optimierung


---
Erstellt für: Coding Challenge - Lead Scoring Engine
Autor: Peter Pfautsch
Datum: November 2025
